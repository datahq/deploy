proxy:
  restart: always
  image: 'dockercloud/haproxy:latest'
  links:
    - frontend
    - assembler
    - auth
    - rawstore
    - specstore
    - resolver
    - metastore
  ports:
    - '80:80'
  roles:
    - global
  tags:
    - ${PROJECT}-${STAGE}
frontend:
  autoredeploy: false
  restart: always
  image: datopian/frontend:latest
  ports:
    - "4000"
  environment:
    VIRTUAL_HOST: ${DOMAIN},https://${DOMAIN}
    SITE_URL: https://${DOMAIN}
    API_URL: https://${DOMAIN_API}
    BITSTORE_URL: https://${PKGSTORE_BUCKET}
    AUTH_UR: http://auth:8000/
    FLOWMANAGER_URL: http://specstore:8000/
    METASTORE_URL: http://metastore:8000/
    RESOLVER_URL: http://resolver:8000/
    FILEMANAGER_URL: http://filemanager:8000
  tags:
    - ${PROJECT}-${STAGE}
auth:
  autoredeploy: false
  restart: always
  image: datopian/auth
  ports:
    - "8000"
  target_num_containers: 1
  environment:
    VIRTUAL_HOST: ${DOMAIN_API}/auth/*
    GUNICORN_PORT: 8000
    DATABASE_URL: ${RDS_URI}
    EXTERNAL_ADDRESS: ${DOMAIN_API}
    PRIVATE_KEY:
    PUBLIC_KEY:
    GOOGLE_KEY: ${GOOGLE_KEY}
    GOOGLE_SECRET: ${GOOGLE_SECRET}
    GITHUB_KEY:
    GITHUB_SECRET:
  tags:
    - ${PROJECT}-${STAGE}
rawstore:
  autoredeploy: false
  restart: always
  image: 'datopian/bitstore:latest'
  ports:
    - '8000'
  target_num_containers: 1
  links:
    - auth
  environment:
    VIRTUAL_HOST: ${DOMAIN_API}/rawstore/*
    AUTH_SERVER: http://auth:8000
    STORAGE_ACCESS_KEY_ID: ${AWS_ACCESS_KEY}
    STORAGE_SECRET_ACCESS_KEY: ${AWS_SECRET_KEY}
    STORAGE_BUCKET_NAME: ${RAWSTORE_BUCKET}
    STORAGE_PATH_PATTERN: '{md5_hex}{extension}'
  tags:
    - ${PROJECT}-${STAGE}
assembler:
  autoredeploy: false
  restart: always
  environment:
    VIRTUAL_HOST: ${DOMAIN_API}/pipelines/*
    SOURCESPEC_REGISTRY_DB_ENGINE:  ${RDS_URI}
    DPP_BASE_PATH: /pipelines/
    PKGSTORE_BUCKET: ${PKGSTORE_BUCKET}
    AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY}
    AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_KEY}
    DPP_ELASTICSEARCH: ${ELASTICEARCH_URI}
    DPP_REDIS_HOST: redis
    FILEMANAGER_DATABASE_URL: ${RDS_URI}
  image: 'datopian/assembler:latest'
  tags:
    - ${STAGE}-assembler
redis:
  image: 'redis:3.2.11-alpine'
  restart: always
  tags:
    - ${PROJECT}-${STAGE}
specstore:
  autoredeploy: false
  restart: always
  links:
    - auth
    - assembler
  environment:
    VIRTUAL_HOST: ${DOMAIN_API}/source/*
    AUTH_SERVER: auth:8000
    DATABASE_URL:  ${RDS_URI}
    DPP_URL: 'http://assembler:5000/pipelines/'
    EVENTS_ELASTICSEARCH_HOST: ${ELASTICEARCH_URI}
    FLOWMANAGER_HOOK_URL: http://specstore:8000/source/update
    PKGSTORE_BUCKET: ${PKGSTORE_BUCKET}
    AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY}
    AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_KEY}
  expose:
    - '8000'
  image: 'datopian/specstore:latest'
  tags:
    - ${PROJECT}-${STAGE}
resolver:
  autoredeploy: false
  restart: always
  image: 'datopian/resolver:latest'
  ports:
    - '8000'
  links:
    - auth
  environment:
    VIRTUAL_HOST: ${DOMAIN_API}/resolver/*
    AUTH_SERVER: http://auth:8000
  tags:
    - ${PROJECT}-${STAGE}
metastore:
  autoredeploy: false
  restart: always
  image: 'datopian/metastore:latest'
  ports:
    - '8000'
  environment:
    VIRTUAL_HOST: ${DOMAIN_API}/metastore/*
    DATAHUB_ELASTICSEARCH_ADDRESS: ${ELASTICEARCH_URI}
    PRIVATE_KEY:
  tags:
    - ${PROJECT}-${STAGE}
filemanager:
  autoredeploy: false
  restart: always
  image: 'datopian/filemanager:latest'
  ports:
    - '8000${FILEMANAGER_EXPOSE_PORT}'
  environment:
    DATABASE_URL: ${RDS_URI}
  tags:
    - ${PROJECT}-${STAGE}
# so we can ssh in and fix ElasticSearch vm.max_map_count
datadog:
  image: 'datadog/docker-dd-agent:latest'
  deployment_strategy: every_node
  environment:
    API_KEY: ${DATADOG_API}
    HOSTNAME: $DOCKERCLOUD_NODE_HOSTNAME
  privileged: true
  restart: on-failure
  volumes:
    - '/var/run/docker.sock:/var/run/docker.sock'
    - '/proc:/host/proc:ro'
    - '/sys/fs/cgroup:/host/sys/fs/cgroup:ro'
